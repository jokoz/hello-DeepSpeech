开源语音识别DeepSpeech v0.4.1训练中文数据源thchs30

相关脚本：
https://github.com/jokoz/hello-DeepSpeech.git

一  环境
1.创建并进入python隔离环境
virtualenv  -p python3  deepspeech
source deepspeech/bin/activate 
cd deepspeech
git clone https://github.com/mozilla/DeepSpeech.git

pip install -r requirements.txt
pip install deepspeech
pip install $(python util/taskcluster.py --decoder)

python util/taskcluster.py --branch v0.4.1 --target native_client/
python util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --target native_client/

git clone https://github.com/kpu/kenlm && cd kenlm && mkdir -p build && cd build && cmake .. && make -j 4 && make install

二 数据
下载数据
http://www.openslr.org/18/
获取data_thchs30.tgz，解压到DeepSpeech下
目录data_thchs30下执行 ./gencsv.sh 生成 
thchs30-alphabet.txt  汉字表
thchs30-vocabulary.txt  汉语词汇表
thchs30-dev.csv
thchs30-test.csv
thchs30-train.csv

三 生成trie
lmplz -o 5  --discount_fallback  --text thchs30-vocabulary.txt --arpa  thchs30-words.arpa
build_binary trie -q 8 -b 8  -a 64 thchs30-words.arpa thchs30-lm.binary
../native_client/generate_trie thchs30-alphabet.txt thchs30-lm.binary thchs30-trie

四 训练
先用少量数据验证流程，train,test,dev都只用了2个wav数据
./run-thchs30.sh
./native_client/convert_graphdef_memmapped_format --in_graph=thchs30_models/output_graph.pb --out_graph=thchs30_models/output_graph.pbmm

deepspeech --model thchs30_models/output_graph.pbmm --alphabet data_thchs30/thchs30-alphabet.txt --lm data_thchs30/thchs30-lm.binary --trie data_thchs30/thchs30-trie --audio data_thchs30/data/A11_233.wav

效果特别差，没有关系，只是验证流程。

再来全量训练
rm -rf thchs30_checkpoint_dir/ thchs30_models/
nohup ./run-thchs30.sh  all &

跑太久，实在是慢。等我有好机器了，再调整参数跑吧。

